{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 GAN 生成动漫头像\n",
    "#### 参考：\n",
    "* 《深度学习框架 PyTorch 入门与实践》\n",
    "* [PyTorch nn document](https://pytorch.org/docs/stable/nn.html)\n",
    "* [pytorch中ConvTranspose2d的计算公式](https://zhuanlan.zhihu.com/p/39240159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成器\n",
    "* 采用\"上卷积\"，根据噪声输出一张 64*64*3 的图片\n",
    "* `torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)`\n",
    "* 卷积中尺寸变化的公式：`H_{out} = (H_{in} - 1) * stride - 2 * padding + kernel_size`\n",
    "  * 当 kennel size、stride、padding 分别为 4、2、1 是，输出尺寸刚好变成输入的两倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NetG(nn.Module):\n",
    "    \"\"\"\n",
    "    生成器定义                                                                                             \n",
    "    \"\"\"\n",
    "    def __init__(self, opt):\n",
    "        super(NetG, self).__init__()\n",
    "        ngf = opt.ngf  # 生成器 feature map 数\n",
    "        self.main = nn.Sequential(\n",
    "            # 输入是 nz 维度的噪声，可认为其实一个 nz*1*1 的 feature map\n",
    "            nn.ConvTranspose2d(opt.nz, ngf * 8, 4, 1, 0, bias=False),  # 尺寸： 1 -> 4\n",
    "            nn.BatchNorm2d(ngf * 8),  # 对输入数据进行标准化（能让机器学习有效率地学习）\n",
    "            nn.ReLU(True),\n",
    "            # 上一步的输出形状：(ngf*8) * 4 * 4\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),  # 尺寸：4 -> 8\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 上一步的输出形状：(ngf*4) * 8 * 8\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),  # 尺寸：8 -> 16\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # 上一步的输出形状：(ngf*2) * 16 * 16\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),  # 尺寸：16 -> 32\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # 上一步的输出形状：(ngf) * 32 * 32\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),  # 尺寸：32 -> 96\n",
    "            nn.Tanh()  #  将图片的像素归一化至 -1~1\n",
    "            # 输出形状：3 * 96 * 96\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判别器\n",
    "* 采用\"下卷积\"，根据输入的 64\\*64\\*3 的图片，输出图片属于正负样本的分数（概率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NetD(nn.Module):\n",
    "    \"\"\"\n",
    "    判别器定义\n",
    "    \"\"\"\n",
    "    def __init__(self, opt):\n",
    "        super(NetD, self).__init__()\n",
    "        ndf = opt.ndf\n",
    "        self.main = nn.Sequential(\n",
    "            # 输入 3 * 96 * 96\n",
    "            nn.Conv2d(3, ndf, 5, 3, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 输出 (ndf) * 32 * 32\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=False),\n",
    "            # 输出 (ndf*2) * 16 * 16\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 输出 (ndf*4) * 8 * 8\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 输出 (ndf*8) * 4 * 4\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # 输出一个数（概率）\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visdom 可视化封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "import time\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "    \"\"\"\n",
    "    封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n",
    "    调用原生的visdom接口\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env='default', **kwargs):\n",
    "        import visdom\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "\n",
    "        # 画的第几个数，相当于横座标\n",
    "        # 保存（’loss',23） 即loss的第23个点\n",
    "        self.index = {}\n",
    "        self.log_text = ''\n",
    "\n",
    "    def reinit(self, env='default', **kwargs):\n",
    "        \"\"\"\n",
    "        修改visdom的配置\n",
    "        \"\"\"\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def plot_many(self, d):\n",
    "        \"\"\"\n",
    "        一次plot多个\n",
    "        @params d: dict (name,value) i.e. ('loss',0.11)\n",
    "        \"\"\"\n",
    "        for k, v in d.items():\n",
    "            self.plot(k, v)\n",
    "\n",
    "    def img_many(self, d):\n",
    "        for k, v in d.items():\n",
    "            self.img(k, v)\n",
    "\n",
    "    def plot(self, name, y):\n",
    "        \"\"\"\n",
    "        self.plot('loss',1.00)\n",
    "        \"\"\"\n",
    "        x = self.index.get(name, 0)\n",
    "        self.vis.line(Y=np.array([y]), X=np.array([x]),\n",
    "                      win=(name),\n",
    "                      opts=dict(title=name),\n",
    "                      update=None if x == 0 else 'append'\n",
    "                      )\n",
    "        self.index[name] = x + 1\n",
    "\n",
    "    def img(self, name, img_):\n",
    "        \"\"\"\n",
    "        self.img('input_img',t.Tensor(64,64))\n",
    "        \"\"\"\n",
    "\n",
    "        if len(img_.size()) < 3:\n",
    "            img_ = img_.cpu().unsqueeze(0)\n",
    "        self.vis.image(img_.cpu(), win=(name), opts=dict(title=name) )\n",
    "\n",
    "    def img_grid_many(self, d):\n",
    "        for k, v in d.items():\n",
    "            self.img_grid(k, v)\n",
    "\n",
    "    def img_grid(self, name, input_3d):\n",
    "        \"\"\"\n",
    "        一个batch的图片转成一个网格图，i.e. input（36，64，64）\n",
    "        会变成 6*6 的网格图，每个格子大小64*64\n",
    "        \"\"\"\n",
    "        self.img(name, tv.utils.make_grid(\n",
    "            input_3d.cpu()[0].unsqueeze(1).clamp(max=1, min=0)))\n",
    "\n",
    "    def log(self, info, win='log_text'):\n",
    "        \"\"\"\n",
    "        self.log({'loss':1,'lr':0.0001})\n",
    "        \"\"\"\n",
    "\n",
    "        self.log_text += ('[{time}] {info} <br>'.format(\n",
    "            time=time.strftime('%m%d_%H%M%S'),\n",
    "            info=info))\n",
    "        self.vis.text(self.log_text, win=win)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.vis, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 参数、数据集加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import torch as t\n",
    "import torchvision as tv\n",
    "from torch.autograd import Variable\n",
    "from torchnet.meter import AverageValueMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"\n",
    "    配置信息                                                                                          \n",
    "    \"\"\"\n",
    "    data_path = '/home/centos/leon/gan_data/'  # 数据集存放路径\n",
    "    num_workers = 1  # 多进程加载数据所用的进程数\n",
    "    image_size = 96  # 图片尺寸\n",
    "    batch_size = 128\n",
    "    max_epoch = 200\n",
    "    lr1 = 2e-4  # 生成器的学习率\n",
    "    lr2 = 2e-4  # 判别器的学习率\n",
    "    beta1 = 0.5  # Adam 优化器的 beta1 参数\n",
    "    use_gpu = False  # 是否使用 GPU\n",
    "    nz = 100  # 噪声维度\n",
    "    ngf = 64  # 生成器的 feature map 数\n",
    "    ndf = 64  # 判别器的 feature map 数\n",
    "    \n",
    "    save_path = '/home/centos/leon/machine_learning_jupyter/neural_network/gan_demo/imgs/'  # 生成图片保存路径\n",
    "    \n",
    "    vis = True  # 是否使用 visdom 可视化\n",
    "    env = 'GAN'  # visdom 的 env\n",
    "    plot_every = 20  # 每间隔 20 batch，visdom 画图一次\n",
    "    \n",
    "    debug_file = '/tmp/debuggan'  # 存在该文件则进入 debug 模式\n",
    "    d_every = 1  # 每 1 个 batch 训练一次判别器\n",
    "    g_every = 5  # 每 5 个 batch 训练一次生成器\n",
    "    decay_every = 10  # 每 10 个 epoch 保存一次模型\n",
    "    netd_path = '/home/centos/leon/machine_learning_jupyter/neural_network/gan_demo/checkpoints/netd.pth'  # 预训练模型\n",
    "    netg_path = '/home/centos/leon/machine_learning_jupyter/neural_network/gan_demo/checkpoints/netg.pth'\n",
    "    \n",
    "    # 测试时用的参数\n",
    "    gen_img = 'result.png'\n",
    "    # 从 512 张生成的图片中保存最好的 64 张\n",
    "    gen_num = 64\n",
    "    gen_search_num = 512\n",
    "    gen_mean = 0  # 噪声的均值\n",
    "    gen_std = 1  # 噪声的方差\n",
    "\n",
    "opt = Config()\n",
    "# 数据加载\n",
    "transforms = tv.transforms.Compose([\n",
    "    tv.transforms.Scale(opt.image_size), \n",
    "    tv.transforms.CenterCrop(opt.image_size), \n",
    "    tv.transforms.ToTensor(), \n",
    "    tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n",
    "    ])\n",
    "dataset = tv.datasets.ImageFolder(opt.data_path, transform=transforms)\n",
    "dataloader = t.utils.data.DataLoader(dataset=dataset, \n",
    "                                     batch_size=opt.batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=opt.num_workers,\n",
    "                                     drop_last=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:22, 22.05s/it]\u001b[A\n",
      "2it [00:34, 19.15s/it]\u001b[A\n",
      "3it [00:46, 17.14s/it]\u001b[A\n",
      "4it [00:58, 15.58s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "def train(**kwargs):\n",
    "    for k_, v_ in kwargs.items():\n",
    "        setattr(opt, k_, v_)\n",
    "    if opt.vis:\n",
    "        vis = Visualizer(opt.env)\n",
    "\n",
    "    transforms = tv.transforms.Compose([\n",
    "        tv.transforms.Scale(opt.image_size),\n",
    "        tv.transforms.CenterCrop(opt.image_size),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    dataset = tv.datasets.ImageFolder(opt.data_path, transform=transforms)\n",
    "    dataloader = t.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=opt.batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=opt.num_workers,\n",
    "                                         drop_last=True\n",
    "                                         )\n",
    "\n",
    "    # 定义网络\n",
    "    netg, netd = NetG(opt), NetD(opt)\n",
    "    map_location = lambda storage, loc: storage\n",
    "    if os.path.exists(opt.netd_path):\n",
    "        netd.load_state_dict(t.load(opt.netd_path, map_location=map_location))\n",
    "    if os.path.exists(opt.netg_path):\n",
    "        netg.load_state_dict(t.load(opt.netg_path, map_location=map_location))\n",
    "\n",
    "    # 定义优化器和损失\n",
    "    optimizer_g = t.optim.Adam(netg.parameters(), opt.lr1, betas=(opt.beta1, 0.999))\n",
    "    optimizer_d = t.optim.Adam(netd.parameters(), opt.lr2, betas=(opt.beta1, 0.999))\n",
    "    criterion = t.nn.BCELoss()\n",
    "\n",
    "    # 真图片label为1，假图片label为0\n",
    "    # noises为生成网络的输入\n",
    "    true_labels = Variable(t.ones(opt.batch_size))\n",
    "    fake_labels = Variable(t.zeros(opt.batch_size))\n",
    "    fix_noises = Variable(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "    noises = Variable(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "\n",
    "    errord_meter = AverageValueMeter()\n",
    "    errorg_meter = AverageValueMeter()\n",
    "\n",
    "    if opt.use_gpu:\n",
    "        netd.cuda()\n",
    "        netg.cuda()\n",
    "        criterion.cuda()\n",
    "        true_labels, fake_labels = true_labels.cuda(), fake_labels.cuda()\n",
    "        fix_noises, noises = fix_noises.cuda(), noises.cuda()\n",
    "\n",
    "    epochs = range(opt.max_epoch)\n",
    "    for epoch in iter(epochs):\n",
    "        for ii, (img, _) in tqdm.tqdm(enumerate(dataloader)):\n",
    "            real_img = Variable(img)\n",
    "            if opt.use_gpu:\n",
    "                real_img = real_img.cuda()\n",
    "            if ii % opt.d_every == 0:\n",
    "                # 训练判别器\n",
    "                optimizer_d.zero_grad()\n",
    "                ## 尽可能的把真图片判别为正确\n",
    "                output = netd(real_img)\n",
    "                error_d_real = criterion(output, true_labels)\n",
    "                error_d_real.backward()\n",
    "\n",
    "                ## 尽可能把假图片判别为错误\n",
    "                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "                fake_img = netg(noises).detach()  # 根据噪声生成假图\n",
    "                output = netd(fake_img)\n",
    "                error_d_fake = criterion(output, fake_labels)\n",
    "                error_d_fake.backward()\n",
    "                optimizer_d.step()\n",
    "\n",
    "                error_d = error_d_fake + error_d_real\n",
    "\n",
    "                errord_meter.add(error_d.data[0])\n",
    "\n",
    "            if ii % opt.g_every == 0:\n",
    "                # 训练生成器\n",
    "                optimizer_g.zero_grad()\n",
    "                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "                fake_img = netg(noises)\n",
    "                output = netd(fake_img)\n",
    "                error_g = criterion(output, true_labels)\n",
    "                error_g.backward()\n",
    "                optimizer_g.step()\n",
    "                errorg_meter.add(error_g.data[0])\n",
    "\n",
    "            if opt.vis and ii % opt.plot_every == 0:\n",
    "                ## 可视化\n",
    "                fix_fake_imgs = netg(fix_noises)\n",
    "                vis.images(fix_fake_imgs.data.cpu().numpy()[:64] * 0.5 + 0.5, win='fixfake')\n",
    "                vis.images(real_img.data.cpu().numpy()[:64] * 0.5 + 0.5, win='real')\n",
    "                vis.plot('errord', errord_meter.value()[0])\n",
    "                vis.plot('errorg', errorg_meter.value()[0])\n",
    "\n",
    "        if epoch % opt.decay_every == 0:\n",
    "            # 保存模型、图片\n",
    "            tv.utils.save_image(fix_fake_imgs.data[:64], '%s/%s.png' % (opt.save_path, epoch), normalize=True,\n",
    "                                range=(-1, 1))\n",
    "            t.save(netd.state_dict(), opt.netd_path.replace('netd.pth', 'netd_{}.pth').format(epoch))\n",
    "            t.save(netg.state_dict(), opt.netg_path.replace('netg.pth', 'netg_{}.pth').format(epoch))\n",
    "            errord_meter.reset()\n",
    "            errorg_meter.reset()\n",
    "            optimizer_g = t.optim.Adam(netg.parameters(), opt.lr1, betas=(opt.beta1, 0.999))\n",
    "            optimizer_d = t.optim.Adam(netd.parameters(), opt.lr2, betas=(opt.beta1, 0.999))\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
